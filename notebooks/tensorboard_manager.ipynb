{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b308beaf",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d258a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "WORK_DIR = '/Users/ariskoutris/Library/CloudStorage/OneDrive-Personal/Programming/wordnet_diffusion'\n",
    "DATA_DIR = f'{WORK_DIR}/data'\n",
    "IMG_DIR = f'{DATA_DIR}/images'\n",
    "VEC_DIR = f'{DATA_DIR}/vectors'\n",
    "LOG_DIR = f'{DATA_DIR}/tensorboard_logs'\n",
    "HIERARCHY_DIR = f'{DATA_DIR}/hierarchies'\n",
    "\n",
    "# Default category to process\n",
    "root_category = 'Dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5e91f3c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = [\".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\", \".PNG\", \n",
    "                  \".ppm\", \".PPM\", \".bmp\", \".BMP\", \".tiff\"]\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "def make_dataset(dir_path):\n",
    "    images = []\n",
    "    assert os.path.isdir(dir_path), f\"{dir_path} is not a valid directory\"\n",
    "    for root, _, fnames in os.walk(dir_path):\n",
    "        for fname in fnames:\n",
    "            if is_image_file(fname):\n",
    "                path = os.path.join(root, fname)\n",
    "                images.append(path)\n",
    "    return images\n",
    "\n",
    "def normalize(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def clear_directory(dir_path):\n",
    "    if os.path.exists(dir_path):\n",
    "        shutil.rmtree(dir_path)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "def extract_metadata_from_paths(img_paths):\n",
    "    segmented_paths = [path.replace('\\\\','/').split('/') for path in img_paths]\n",
    "    filenames = [path[-1] for path in segmented_paths]\n",
    "    dates = [path[-2] for path in segmented_paths]\n",
    "    labels = [path[-3] for path in segmented_paths]\n",
    "    seq_nums = [fname.split('-')[0] for fname in filenames]\n",
    "    seeds = [fname.split('-')[1].split('.')[0] for fname in filenames]\n",
    "    ids = ['-'.join([date, seq_num, seed]) for (date, seq_num, seed) in zip(dates, seq_nums, seeds)]\n",
    "    \n",
    "    return {\n",
    "        'ids': ids,\n",
    "        'labels': labels,\n",
    "        'seq_nums': seq_nums, \n",
    "        'seeds': seeds,\n",
    "        'dates': dates,\n",
    "        'filenames': filenames\n",
    "    }\n",
    "\n",
    "def load_images(img_paths, target_size=(224, 224)):\n",
    "    images = []\n",
    "    for path in img_paths:\n",
    "        img = load_img(path, target_size=target_size)\n",
    "        img_arr = img_to_array(img)\n",
    "        images.append(img_arr)\n",
    "    return images\n",
    "\n",
    "def register_embedding(embedding_tensor_name, meta_data_fname, log_dir):\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = embedding_tensor_name\n",
    "    embedding.metadata_path = meta_data_fname\n",
    "    projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ef460",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Setup directories\n",
    "if clear_logs:\n",
    "    clear_directory(LOG_DIR)\n",
    "\n",
    "# Load images\n",
    "img_paths = make_dataset(os.path.join(IMG_DIR, category))\n",
    "metadata = extract_metadata_from_paths(img_paths)\n",
    "\n",
    "# Create metadata dataframe\n",
    "metadata_df = pd.DataFrame({\n",
    "    'id': metadata['ids'],\n",
    "    'class_name': metadata['labels'],\n",
    "    'sequence_number': metadata['seq_nums'],\n",
    "    'seed': metadata['seeds'],\n",
    "    'date_created': metadata['dates'],\n",
    "    'filename': metadata['filenames'],\n",
    "    'path': img_paths\n",
    "})\n",
    "\n",
    "vecs = np.load(os.path.join(VEC_DIR, 'npy', f'{category.lower()}.npy'))\n",
    "\n",
    "# Import wordnet hierarchy\n",
    "hier_df = pd.read_csv(os.path.join(HIERARCHY_DIR, f\"{category.casefold()}.csv\"))\n",
    "\n",
    "# Merge metadata with hierarchy\n",
    "tensorboard_metadata = metadata_df.reset_index().merge(\n",
    "    hier_df, left_on='class_name', right_on='class', suffixes=['','_y'])\n",
    "\n",
    "# Get indices of merged data for selecting vectors\n",
    "indices = tensorboard_metadata['index'].values\n",
    "\n",
    "# Select relevant columns and clean data\n",
    "tensorboard_metadata = tensorboard_metadata[\n",
    "    ['class', 'cat_depth_0', 'cat_depth_1', 'cat_depth_2', 'frequency']\n",
    "].fillna('None')\n",
    "\n",
    "# Setup Tensorboard projection\n",
    "PROJ_DIR = LOG_DIR\n",
    "META_DATA_FNAME = f'meta_{category.casefold()}.tsv'\n",
    "EMBEDDINGS_TENSOR_NAME = f'embeddings_{category.casefold()}'\n",
    "EMBEDDINGS_FPATH = os.path.join(PROJ_DIR, EMBEDDINGS_TENSOR_NAME + '.ckpt')\n",
    "\n",
    "# Save metadata for Tensorboard\n",
    "tensorboard_metadata.to_csv(\n",
    "    os.path.join(PROJ_DIR, META_DATA_FNAME), sep='\\t', index=False)\n",
    "\n",
    "# Register embedding configuration\n",
    "register_embedding(EMBEDDINGS_TENSOR_NAME, META_DATA_FNAME, PROJ_DIR)\n",
    "\n",
    "# Save embeddings for Tensorboard\n",
    "tensor_embeddings = tf.Variable(vecs[indices], name=EMBEDDINGS_TENSOR_NAME)\n",
    "saver = tf.compat.v1.train.Saver([tensor_embeddings])\n",
    "_ = saver.save(sess=None, global_step=0, save_path=EMBEDDINGS_FPATH)\n",
    "\n",
    "print(f\"Tensorboard visualization prepared for {category}\")\n",
    "print(f\"To view, run: tensorboard --logdir={LOG_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
